{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81452969",
   "metadata": {},
   "source": [
    "# Breast Cancer Wisconsin - Diagnostic Dataset Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac1639",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8577ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "from IPython.display import display, Markdown, Latex\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import *\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768cd0a",
   "metadata": {},
   "source": [
    "___\n",
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca1dc8",
   "metadata": {},
   "source": [
    "### Load, Clean, & Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "df = pd.read_csv('data.csv')\n",
    "display(df.head())\n",
    "\n",
    "# Clean\n",
    "df.drop(columns=['Unnamed: 32', 'id'], inplace=True)\n",
    "df['diagnosis'] = [1 if row[1]['diagnosis'] == 'M' else 0 for row in df.iterrows()]\n",
    "display(df.head())\n",
    "\n",
    "# Standardize\n",
    "features = list(df.columns)\n",
    "features.remove('diagnosis')\n",
    "for col in features:\n",
    "    df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "display(df.head())\n",
    "\n",
    "y = df['diagnosis']\n",
    "x = df.loc[:, df.columns != 'diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc826455",
   "metadata": {},
   "source": [
    "___\n",
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baec90de",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47761bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.sort_index(axis=1).corr()\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(corr, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942c191",
   "metadata": {},
   "source": [
    "### Features Visualized via Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "chart = sns.boxplot(data=df)\n",
    "chart.set_xticklabels(labels=df.columns, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01904c",
   "metadata": {},
   "source": [
    "### Histogram Analysis: Benign vs. Malignant Tumors Across Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_columns = 5\n",
    "subplot_rows = 6\n",
    "f, axs = plt.subplots(subplot_rows,subplot_columns,figsize=(15,15))\n",
    "\n",
    "num = 1\n",
    "for column in df.columns:\n",
    "    if df[column].dtypes != 'float64':\n",
    "        continue\n",
    "    \n",
    "    bins = 25\n",
    "    plt.subplot(subplot_rows,subplot_columns,num)\n",
    "    # plt.hist(df[column], bins=25, alpha=0.0, label='A', color='b')\n",
    "    plt.hist(df[df['diagnosis'] == 1][column], bins=bins, alpha=0.5, label='M', color='r')\n",
    "    plt.hist(df[df['diagnosis'] == 0][column], bins=bins, alpha=0.5, label='B', color='g')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(column)\n",
    "    \n",
    "    num += 1\n",
    "\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a85fc5",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b89ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(x.cov())\n",
    "eig_percents = eig_vals / sum(eig_vals) * 100\n",
    "\n",
    "sort_ix,  sort_eig_percents = zip(*sorted(enumerate(eig_percents), reverse = True, key = lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8728a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'PC{i + 1}' for i,v in enumerate(sort_eig_percents)]\n",
    "sns.set(rc={'figure.figsize':(20,5)})\n",
    "ax = sns.barplot(x=labels, y=list(sort_eig_percents), color='cornflowerblue')\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "ax.set_title('Pricipal Components & Percent of Varation Explained', fontsize=15)\n",
    "ax.set_xlabel('Pricipal Components', fontsize=12)\n",
    "ax.set_ylabel('Percent of Varation Explained', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ef0b9",
   "metadata": {},
   "source": [
    "___\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad9324",
   "metadata": {},
   "source": [
    "### Final Data Preparation Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35615f4a",
   "metadata": {},
   "source": [
    "#### Create Condensed Feature List with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1773d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(x)\n",
    "x_ENG = pca.transform(x)\n",
    "print(x.shape, x_ENG.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f0ed3",
   "metadata": {},
   "source": [
    "#### Visualize PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b20adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame({\"PC1\":x_ENG[:,0],\"PC2\":x_ENG[:,1],})\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel(f\"PC 1:  {eig_percents[0]:.2f}% \" ,fontsize = 12)\n",
    "plt.ylabel(f\"PC 2:  {eig_percents[1]:.2f}% \" ,fontsize = 12)\n",
    "plt.title(\"Principal Component Analysis of Breast Cancer Dataset\",fontsize=15)\n",
    "targets = [0, 1]\n",
    "colors = ['g','r']\n",
    "labs = ['Begnign','Malignant']\n",
    "\n",
    "for target, color, lab in zip(targets,colors,labs):\n",
    "    indicesToKeep = df['diagnosis'] == target\n",
    "    plt.scatter(principal_df.loc[indicesToKeep, 'PC1'],\n",
    "                principal_df.loc[indicesToKeep, 'PC2'], c = color, s = 50, label = lab);\n",
    "\n",
    "plt.legend(prop={'size': 15});\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ca327",
   "metadata": {},
   "source": [
    "#### Create Function for Flagging Correlated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94403d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlated(dataset, threshold=0.9):\n",
    "    '''\n",
    "    This function returns attributes that are correlated more than a given a threshold i.e. 90%\n",
    "    '''\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold:\n",
    "                # print(corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i,j])\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d0ba03",
   "metadata": {},
   "source": [
    "#### Create DataFrame with Correlated Features Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aeddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_minus_corr = x.copy(deep=True)\n",
    "features_to_drop = correlated(x_minus_corr)\n",
    "x_minus_corr = x_minus_corr.drop(features_to_drop,axis=1)\n",
    "print(f'Correlated Features Removed:')\n",
    "for col in features_to_drop:\n",
    "    print(f'\\t{col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23b8468",
   "metadata": {},
   "source": [
    "#### Create Testing & Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "# All Features\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Correlated Features Removed\n",
    "x_train_CORR, x_test_CORR, y_train, y_test = train_test_split(x_minus_corr, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# PCA Dataset\n",
    "x_train_ENG, x_test_ENG, y_train, y_test = train_test_split(x_ENG, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738ff4ea",
   "metadata": {},
   "source": [
    "#### Our Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models = [('Logistic Regression', LogisticRegression(solver='lbfgs')),\n",
    "              ('Random Forest', RandomForestClassifier()),\n",
    "              ('Gradient Boosting', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)),\n",
    "              ('KNeighbors Classifier', KNeighborsClassifier(n_neighbors=3))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c61467",
   "metadata": {},
   "source": [
    "### Classification Testing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa04f8b",
   "metadata": {},
   "source": [
    "#### Create Function - Run Single Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(classifier, x_train, y_train, x_test, y_test, print_stats=False):\n",
    "    \n",
    "    '''\n",
    "    This function returns a classification and confusion matrix for a given classification model\n",
    "    This function accepts a classifier type + training and testing data as parameters\n",
    "    '''\n",
    "    \n",
    "    clf = classifier[1]\n",
    "    clf.fit(x_train, y_train)\n",
    "    predictions = clf.predict(x_test)\n",
    "    \n",
    "    if print_stats==True:\n",
    "        display(Markdown(f'#### {classifier[0]} \\n'))\n",
    "        print(classification_report(y_test, predictions, target_names=['Benign (0)', 'Malignant (1)']))\n",
    "        \n",
    "        scores = cross_val_score(clf, x, y, cv=5)\n",
    "        print('\\nCross-Validation Results:')\n",
    "        print(\"\\t%0.2f accuracy with a standard deviation of %0.2f\\n\" % (scores.mean(), scores.std()))\n",
    "        \n",
    "        cm = confusion_matrix(y_test, predictions)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Benign (0)', 'Malignant (1)'])\n",
    "        disp.plot()\n",
    "        plt.show()\n",
    "    \n",
    "    if classifier[0] == 'Logistic Regression':\n",
    "        importance = clf.coef_[0]\n",
    "    elif classifier[0] == 'Random Forest':\n",
    "        importance = clf.feature_importances_\n",
    "    elif classifier[0] == 'Gradient Boosting':\n",
    "        importance = clf.feature_importances_\n",
    "    else:\n",
    "        importance = []\n",
    "    \n",
    "    return predictions, importance, clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6be7154",
   "metadata": {},
   "source": [
    "#### Create Function - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe50a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(x, y, model, test_size=0.2, random_state=42):\n",
    "    \n",
    "    '''\n",
    "    This function will run a classification model with one feature type at a time\n",
    "    It will then compare the performance of the single feature type model to the performance of the full model\n",
    "    The function will output a grid displaying the performance comparison\n",
    "    '''\n",
    "    \n",
    "    column_types = defaultdict(list)\n",
    "    for column in x.columns:\n",
    "        column_types[column.split('_')[0]].append(column)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    predictions_og, importance_og, score_og = run_classifier(model, x_train, y_train, x_test, y_test)\n",
    "    precision_og = precision_score(y_test, predictions_og)\n",
    "    recall_og = recall_score(y_test, predictions_og)\n",
    "    importance_df = pd.DataFrame(columns = ['model_type', 'feature_type', 'r2_all', 'r2_one', 'r2_diff', 'prec_all', 'prec_one', 'prec_diff', 'prec_diff_pct', 'recall_all', 'recall_one', 'recall_diff', 'recall_diff_pct'])\n",
    "    for column_type, columns in column_types.items():\n",
    "        x_imp = x.copy()\n",
    "        x_imp = x_imp[columns]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_imp, y, test_size=test_size, random_state=random_state)\n",
    "        predictions_new, importance_new, score_new = run_classifier(model, x_train, y_train, x_test, y_test)\n",
    "        precision_new = precision_score(y_test, predictions_new)\n",
    "        recall_new = recall_score(y_test, predictions_new)\n",
    "        importance_df = importance_df.append({'model_type': model[0],\n",
    "                                              'feature_type': column_type,\n",
    "                                              'r2_all': score_og,\n",
    "                                              'r2_one': score_new,\n",
    "                                              'r2_diff': score_new - score_og,\n",
    "                                              'r2_dff_pct': np.NaN,\n",
    "                                              'prec_all': precision_og,\n",
    "                                              'prec_one': precision_new,\n",
    "                                              'prec_diff': precision_new - precision_og,\n",
    "                                              'prec_diff_pct': np.NaN,\n",
    "                                              'recall_all': recall_og,\n",
    "                                              'recall_one': recall_new,\n",
    "                                              'recall_diff': recall_new - recall_og,\n",
    "                                              'recall_diff_pct': np.NaN}, ignore_index=True)\n",
    "    importance_df['r2_dff_pct'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in importance_df['r2_diff']], index = importance_df.index)\n",
    "    importance_df['prec_diff_pct'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in importance_df['prec_diff']], index = importance_df.index)\n",
    "    importance_df['recall_diff_pct'] = pd.Series([\"{0:.2f}%\".format(val * 100) for val in importance_df['recall_diff']], index = importance_df.index)\n",
    "    importance_df = importance_df.drop(['r2_all', 'r2_one', 'r2_diff', 'r2_dff_pct'], axis=1)\n",
    "    display(importance_df.sort_values(by=['recall_diff']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab1f49",
   "metadata": {},
   "source": [
    "## Classification Testing (All Features)\n",
    "In this section we seek to establish a baseline by running our classifiers with all features included and examining performance and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 1\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train, y_train, x_test, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e244c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 2\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train, y_train, x_test, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 3\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train, y_train, x_test, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 4\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train, y_train, x_test, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20da04",
   "metadata": {},
   "source": [
    "#### Identify Most Important Features Pt. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f98445",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, importance, score = run_classifier(clf_models[0], x_train, y_train, x_test, y_test)\n",
    "ax = sns.barplot(y=importance, x=x.columns, color='cornflowerblue')\n",
    "ax.set_xticklabels(x.columns, rotation=90)\n",
    "ax.set_title(f'Feature Importance: {clf_models[0][0]}', fontsize=15)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.set_ylabel('Importance', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d60e4",
   "metadata": {},
   "source": [
    "#### Identify Most Important Features Pt. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e9bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(x, y, clf_models[0], test_size, random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e71187",
   "metadata": {},
   "source": [
    "## Classification Testing (Correlated Features Removed)\n",
    "\n",
    "In this section we seek to understand the impact that removing highly correlated features has on predictive performance & feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 1\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train_CORR, y_train, x_test_CORR, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e73a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 2\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train_CORR, y_train, x_test_CORR, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b00a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 3\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train_CORR, y_train, x_test_CORR, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 4\n",
    "p,i,r2 = run_classifier(clf_models[model_num - 1], x_train_CORR, y_train, x_test_CORR, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff35d20",
   "metadata": {},
   "source": [
    "#### Identify Most Important Features Pt. 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c09831",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, importance, score = run_classifier(clf_models[0], x_train_CORR, y_train, x_test_CORR, y_test)\n",
    "ax = sns.barplot(y=importance, x=x_minus_corr.columns, color='cornflowerblue')\n",
    "ax.set_xticklabels(x_minus_corr.columns, rotation=90)\n",
    "ax.set_title(f'Feature Importance: {clf_models[0][0]}', fontsize=15)\n",
    "ax.set_xlabel('Feature', fontsize=12)\n",
    "ax.set_ylabel('Importance', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ccfdd",
   "metadata": {},
   "source": [
    "#### Identify Most Important Features Pt. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(x_minus_corr, y, clf_models[0], test_size, random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c364db7",
   "metadata": {},
   "source": [
    "## Classification Testing (w/ PCA)\n",
    "\n",
    "In this section we seek to analyze the performance of the models when utilizing a dataset that has had its dimensions reduced via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 1\n",
    "predictions, importance, score = run_classifier(clf_models[model_num - 1], x_train_ENG, y_train, x_test_ENG, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7305c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 2\n",
    "predictions, importance, score = run_classifier(clf_models[model_num - 1], x_train_ENG, y_train, x_test_ENG, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 3\n",
    "predictions, importance, score = run_classifier(clf_models[model_num - 1], x_train_ENG, y_train, x_test_ENG, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b019688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 4\n",
    "predictions, importance, score = run_classifier(clf_models[model_num - 1], x_train_ENG, y_train, x_test_ENG, y_test, print_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e11cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golden_scenario_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba74fb18df6ae5e850afdfbaf51396e56520b6dd418e28b9cd93530af8d0cc7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
